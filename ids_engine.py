#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
1. Thu th·∫≠p g√≥i tin (sniff) theo giao di·ªán c·∫•u h√¨nh
2. Gom nh√≥m th√†nh lu·ªìng (flow) v√† duy tr√¨ tr·∫°ng th√°i FlowState
3. T√≠nh ƒë·∫∑c tr∆∞ng g·∫ßn gi·ªëng NSL-KDD + ƒë·∫∑c tr∆∞ng b·ªï sung (t·ªëc ƒë·ªô, is_https...)
4. Ch·∫°y qua pipeline ti·ªÅn x·ª≠ l√Ω + m√¥ h√¨nh ML/DL (t·ª± ƒë·ªông t·∫£i d·ª±a metrics)
5. √Åp d·ª•ng heuristics h·∫≠u x·ª≠ l√Ω ƒë·ªÉ gi·∫£m false positive
6. K·∫øt h·ª£p nhi·ªÅu detector chuy√™n bi·ªát: SYN/UDP/ICMP Flood (global & distributed), Port Scan
7. ƒê·∫©y c·∫£nh b√°o sang h√†ng ƒë·ª£i cho notifier + giao di·ªán web

Thi·∫øt k·∫ø hot-reload: apply_config() cho ph√©p c·∫≠p nh·∫≠t ng∆∞·ª°ng, c·ª≠a s·ªï, m√¥ h√¨nh
kh√¥ng c·∫ßn kh·ªüi ƒë·ªông l·∫°i thread sniffing.
"""

import os
import time
import queue
import threading
import configparser
from collections import defaultdict, deque
from datetime import datetime, timezone

import numpy as np
import pandas as pd

from detectors.port_scan import PortScanDetector

# Gi·∫£m log TF (n·∫øu m√¥i tr∆∞·ªùng c√≥ c√†i TF)
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
from scapy.all import sniff, IP, TCP, UDP

# Internal modules
from logging_utils import setup_logging
from ids_utils import (
    TRUSTED_DOMAINS,
    proto_name,
    guess_service,
)
from flow_state import FlowState
from detectors.heuristics import (
    is_trusted_source as _h_is_trusted_source,
    post_process_alert as _h_post_process_alert,
    determine_attack_type as _h_determine_attack_type,
)
from detectors.floods import (
    SynFloodGlobalDetector,
    SynFloodDistributedDetector,
    UDPGlobalDetector,
    UDPDistributedDetector,
    ICMPGlobalDetector,
    ICMPDistributedDetector,
)
from detectors.packet_filter import PacketFilter
from model_runtime import load_model_and_preprocess, predict_probabilities
from ids.flow_classifier import FlowClassifier
from ids.alert_manager import AlertManager


class IDSEngine:
    def __init__(self, config_path: str = 'config.ini'):
        # ƒê·ªçc c·∫•u h√¨nh
        config = configparser.ConfigParser()
        config.read(config_path, encoding='utf-8')

    # -------- C·∫•u h√¨nh m·∫°ng / c·ª≠a s·ªï --------
        self.iface = config.get('Network', 'interface')
        self.window = config.getint('Network', 'window')
        self.min_pkts = config.getint('Network', 'min_packets')
        self.min_bytes = config.getint('Network', 'min_bytes')

    # IP c·ª•c b·ªô/m√°y ch·ªß ƒë·ªÉ ph√¢n bi·ªát chi·ªÅu l∆∞u l∆∞·ª£ng (inbound/outbound)
        self.local_ips = set()
        try:
            server_ip = config.get('Network', 'server_ip', fallback='').strip()
            local_ips_str = config.get('Network', 'local_ips', fallback='').strip()
            if server_ip:
                self.local_ips.add(server_ip)
            if local_ips_str:
                for tok in local_ips_str.split(','):
                    tok = tok.strip()
                    if tok:
                        self.local_ips.add(tok)
        except Exception:
            pass

    # -------- C·∫•u h√¨nh m√¥ h√¨nh --------
        self.model_path = config.get('Model', 'model_path')
        self.preprocess_path = config.get('Model', 'preprocess_path')
        self.alert_threshold = config.getfloat('Model', 'threshold')
        # Ng∆∞·ª°ng flood cho lab/production
        try:
            self.dos_packet_rate = config.getint('Model', 'dos_packet_rate', fallback=1000)
        except Exception:
            self.dos_packet_rate = 1000
        try:
            # Th·ªùi gian reset b·ªô ƒë·∫øm flood (gi√¢y) ‚Äì m·∫∑c ƒë·ªãnh 5 ƒë·ªÉ c·∫£nh b√°o nhanh h∆°n
            self.dos_reset_seconds = config.getint('Model', 'dos_reset_seconds', fallback=5)
        except Exception:
            self.dos_reset_seconds = 5

    # -------- C·∫•u h√¨nh l·ªçc g√≥i --------
        self.whitelist_file = config.get('Filtering', 'whitelist_file')
        self.blacklist_file = config.get('Filtering', 'blacklist_file')
        self.ignore_https = config.getboolean('Filtering', 'ignore_https', fallback=False)

    # Logger ghi file t·∫•n c√¥ng
        self.attack_logger = setup_logging()

    # C·ªù tr·∫°ng th√°i
        self.running = False
        self.sniff_thread = None
        self.predict_thread = None

    # N·∫°p whitelist / blacklist t·ª´ file
        self.whitelist = set()
        self.blacklist = set()
        if os.path.exists(self.whitelist_file):
            with open(self.whitelist_file, 'r', encoding='utf-8', errors='ignore') as f:
                self.whitelist = set(line.strip() for line in f if line.strip())
        if os.path.exists(self.blacklist_file):
            with open(self.blacklist_file, 'r', encoding='utf-8', errors='ignore') as f:
                self.blacklist = set(line.strip() for line in f if line.strip())
        # B·ªï sung domain tin c·∫≠y
        self.whitelist.update(TRUSTED_DOMAINS)

    # B·∫£n ƒë·ªì l∆∞u tr·∫°ng th√°i t·ª´ng lu·ªìng + lock b·∫£o v·ªá
        self.flows = {}
        self.lock = threading.Lock()

    # Flow classifier module
        self.flow_classifier = FlowClassifier(config)
        self.flow_classifier.attack_logger = self.attack_logger

    # B·ªô nh·ªõ v√≤ng ƒë·ªÉ t√≠nh c√°c ch·ªâ s·ªë count/srv_count theo c·ª≠a s·ªï
        self.host_events = deque(maxlen=100000)

    # Th·ªëng k√™ ph·ª•c v·ª• UI / gi√°m s√°t
        self.stats = {
            "packets_processed": 0,
            "flows_analyzed": 0,
            "alerts_generated": 0,
            "start_time": None,
            "packets_per_second": 0,
            "last_update_time": time.time(),
            "bytes_processed": 0,
        }

    # Alert queue and manager (must be before PacketFilter and flood detectors)
        self.alert_queue = queue.Queue()
        self.alert_manager = AlertManager(self.alert_queue, self.attack_logger, self.stats)

    # Detector: qu√©t c·ªïng
        try:
            self.port_scan_threshold = config.getint('Filtering', 'port_scan_threshold', fallback=15)
        except Exception:
            self.port_scan_threshold = 15
        self.port_scan = PortScanDetector(threshold=self.port_scan_threshold)

    # Detector: SYN Flood (to√†n c·ª•c + ph√¢n t√°n)
        self.syn_flood_global = SynFloodGlobalDetector(total_threshold=self.dos_packet_rate, reset_seconds=self.dos_reset_seconds)
        self.syn_flood_dist = SynFloodDistributedDetector()
    # Detector: UDP Flood
        self.udp_flood_global = UDPGlobalDetector(total_threshold=self.dos_packet_rate, reset_seconds=self.dos_reset_seconds)
        self.udp_flood_dist = UDPDistributedDetector()
    # Detector: ICMP Flood
        self.icmp_flood_global = ICMPGlobalDetector(total_threshold=self.dos_packet_rate, reset_seconds=self.dos_reset_seconds)
        self.icmp_flood_dist = ICMPDistributedDetector()

    # Packet filter (gom c√°c logic l·ªçc g√≥i ra module ri√™ng)
        self.packet_filter = PacketFilter(
            ignore_https=self.ignore_https,
            whitelist=self.whitelist,
            blacklist=self.blacklist,
            port_scan_detector=self.port_scan,
            attack_logger=self.attack_logger,
            alert_queue=self.alert_manager.alert_queue,
            recent_alerts=self.alert_manager.recent_alerts,
            stats=self.stats,
        )

    # Tr·∫°ng th√°i m√¥ h√¨nh / pipeline ti·ªÅn x·ª≠ l√Ω
        self.model_type = None  # 'dl' ho·∫∑c 'ml'
        self.model = None       # Keras model ho·∫∑c sklearn estimator
        self.preprocess = None  # sklearn ColumnTransformer

    def _should_classify(self, flow_key, flow_data):
        """Delegate to flow_classifier module"""
        return self.flow_classifier.should_classify(flow_key, flow_data)

    # -------- Hot reload configuration (√°p d·ª•ng thay ƒë·ªïi ƒë·ªông) ---------
    def apply_config(self, live_cfg):
        """Update runtime parameters from LiveConfig without restarting threads."""
        try:
            # C·∫≠p nh·∫≠t tham s·ªë c·ª≠a s·ªï / ng∆∞·ª°ng l·ªçc t·ªëi thi·ªÉu
            self.window = live_cfg.getint('Network', 'window', fallback=self.window)
            self.min_pkts = live_cfg.getint('Network', 'min_packets', fallback=self.min_pkts)
            self.min_bytes = live_cfg.getint('Network', 'min_bytes', fallback=self.min_bytes)

            # C·∫≠p nh·∫≠t ng∆∞·ª°ng c·∫£nh b√°o & ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh
            new_model_path = live_cfg.get('Model', 'model_path', fallback=self.model_path)
            new_pre_path = live_cfg.get('Model', 'preprocess_path', fallback=self.preprocess_path)
            self.alert_threshold = live_cfg.getfloat('Model', 'threshold', fallback=self.alert_threshold)

            # N·∫øu ƒë·ªïi file m√¥ h√¨nh / preprocessing => t·∫£i l·∫°i
            if (new_model_path != self.model_path) or (new_pre_path != self.preprocess_path):
                self.model_path = new_model_path
                self.preprocess_path = new_pre_path
                self.load_model()

            # C·∫≠p nh·∫≠t tham s·ªë l·ªçc HTTPS ƒë·ªông
            self.ignore_https = live_cfg.getboolean('Filtering', 'ignore_https', fallback=self.ignore_https)
            if hasattr(self, 'packet_filter'):
                self.packet_filter.ignore_https = self.ignore_https

            # C·∫≠p nh·∫≠t ng∆∞·ª°ng flood ƒë·ªông
            new_dos_pkt = live_cfg.getint('Model', 'dos_packet_rate', fallback=self.dos_packet_rate)
            new_dos_reset = live_cfg.getint('Model', 'dos_reset_seconds', fallback=self.dos_reset_seconds)
            if new_dos_pkt != self.dos_packet_rate or new_dos_reset != self.dos_reset_seconds:
                self.dos_packet_rate = new_dos_pkt
                self.dos_reset_seconds = new_dos_reset
                # √°p d·ª•ng cho 3 detector global
                self.syn_flood_global.total_threshold = self.dos_packet_rate
                self.udp_flood_global.total_threshold = self.dos_packet_rate
                self.icmp_flood_global.total_threshold = self.dos_packet_rate
                self.syn_flood_global.reset_seconds = self.dos_reset_seconds
                self.udp_flood_global.reset_seconds = self.dos_reset_seconds
                self.icmp_flood_global.reset_seconds = self.dos_reset_seconds

            # C·∫≠p nh·∫≠t ng∆∞·ª°ng qu√©t c·ªïng ƒë·ªông n·∫øu thay ƒë·ªïi
            new_ps_threshold = live_cfg.getint('Filtering', 'port_scan_threshold', fallback=self.port_scan_threshold)
            if new_ps_threshold != self.port_scan_threshold:
                self.port_scan_threshold = new_ps_threshold
                self.port_scan.threshold = new_ps_threshold

            # Update flow classifier parameters
            self.flow_classifier.small_flow_threshold = live_cfg.getint('Detection', 'small_flow_threshold', fallback=50)
            self.flow_classifier.small_flow_window = live_cfg.getint('Detection', 'small_flow_window', fallback=5)
            self.flow_classifier.global_flow_threshold = live_cfg.getint('Detection', 'global_flow_threshold', fallback=100)
        except Exception as e:
            print('[Config] Error:', e)

    def _is_local_ip(self, ip: str) -> bool:
        return ip in self.local_ips

    def load_model(self) -> bool:
        print("[*] Loading model...")
        try:
            self.preprocess, self.model, self.model_type, info = load_model_and_preprocess(
                self.preprocess_path, self.model_path
            )
            model_name = info.get('best_ml_name', 'DL') if self.model_type == 'ml' else 'DL'
            print(f"‚úÖ Loaded {model_name} (threshold={self.alert_threshold})")
            return True
        except Exception as e:
            print(f"‚ùå Model load failed: {e}")
            return False

    def _predict_probabilities(self, X: np.ndarray) -> np.ndarray:
        return predict_probabilities(self.model, self.model_type, X)

    def _flow_key(self, pkt):
        sip, dip = pkt[IP].src, pkt[IP].dst
        sport = pkt[TCP].sport if pkt.haslayer(TCP) else (pkt[UDP].sport if pkt.haslayer(UDP) else 0)
        dport = pkt[TCP].dport if pkt.haslayer(TCP) else (pkt[UDP].dport if pkt.haslayer(UDP) else 0)
        proto = proto_name(pkt)
        return (sip, sport, dip, dport, proto)

    def _direction_src_to_dst(self, pkt, key):
        sip, sport, dip, dport, _ = key
        ps, pd = None, None
        if pkt.haslayer(TCP):
            ps, pd = pkt[TCP].sport, pkt[TCP].dport
        elif pkt.haslayer(UDP):
            ps, pd = pkt[UDP].sport, pkt[UDP].dport
        return (pkt[IP].src == sip) and (ps == sport) and (pkt[IP].dst == dip) and (pd == dport)

    def _update_host_window(self, pkt):
        now = time.time()
        dip = pkt[IP].dst
        dport = (pkt[TCP].dport if pkt.haslayer(TCP) else pkt[UDP].dport if pkt.haslayer(UDP) else 0)
        self.host_events.append((now, dip, dport))

    def _build_host_counts(self):
        t0 = time.time() - self.window
        dst_count = defaultdict(int)
        dst_srv_count = defaultdict(int)
        for ts, dip, dport in list(self.host_events):
            if ts >= t0:
                dst_count[("dst", dip)] += 1
                dst_srv_count[("dst_srv", (dip, dport))] += 1
        counts = {}
        counts.update(dst_count)
        counts.update(dst_srv_count)
        return counts

    def _packet_cb(self, pkt):
        try:
            if not pkt.haslayer(IP):
                return

            # Th·ªëng k√™ c∆° b·∫£n
            self.stats["packets_processed"] += 1
            self.stats["bytes_processed"] += len(pkt)
            
            now = time.time()
            if now - self.stats["last_update_time"] >= 1:
                if self.stats["start_time"]:
                    self.stats["packets_per_second"] = int(self.stats["packets_processed"] / (now - self.stats["start_time"]))
                self.stats["last_update_time"] = now

            # Flood detectors (to√†n c·ª•c) ‚Äì ch·∫°y tr∆∞·ªõc ƒë·ªÉ ph√°t hi·ªán s·ªõm t·∫•n c√¥ng volumetric
            # SYN flood: ch·ªâ x√©t SYN kh·ªüi t·∫°o (SYN=1, ACK=0) ƒë·ªÉ tr√°nh t√≠nh c·∫£ SYN-ACK
            if pkt.haslayer(TCP):
                _flags = int(pkt[TCP].flags)
                _is_syn = (_flags & 0x02) != 0
                _is_ack = (_flags & 0x10) != 0
                if _is_syn and not _is_ack:
                    self.syn_flood_global.process(
                        pkt,
                        is_trusted_source_fn=self._is_trusted_source,
                        window_seconds=self.window,
                        attack_logger=self.attack_logger,
                        alert_queue=self.alert_manager.alert_queue,
                        recent_alerts=self.alert_manager.recent_alerts,
                        stats=self.stats,
                    )
            # UDP flood
            self.udp_flood_global.process(
                pkt,
                is_trusted_source_fn=self._is_trusted_source,
                window_seconds=self.window,
                attack_logger=self.attack_logger,
                alert_queue=self.alert_manager.alert_queue,
                recent_alerts=self.alert_manager.recent_alerts,
                stats=self.stats,
            )
            # ICMP flood
            self.icmp_flood_global.process(
                pkt,
                is_trusted_source_fn=self._is_trusted_source,
                window_seconds=self.window,
                attack_logger=self.attack_logger,
                alert_queue=self.alert_manager.alert_queue,
                recent_alerts=self.alert_manager.recent_alerts,
                stats=self.stats,
            )

            # B∆∞·ªõc l·ªçc g√≥i tr∆∞·ªõc khi c·∫≠p nh·∫≠t tr·∫°ng th√°i lu·ªìng
            if not self.packet_filter.should_process(pkt):
                return

            # C·∫≠p nh·∫≠t ho·∫∑c kh·ªüi t·∫°o FlowState
            key = self._flow_key(pkt)
            with self.lock:
                is_new = key not in self.flows
                if is_new:
                    self.flows[key] = FlowState(proto_name(pkt), guess_service(pkt))
                state = self.flows[key]
                direction = self._direction_src_to_dst(pkt, key)
                state.update(pkt, direction)
                self._update_host_window(pkt)

        except Exception as e:
            if isinstance(e, (AttributeError, IndexError)) and ('sport' in str(e) or 'dport' in str(e)):
                pass
            else:
                print(f"CB error: {type(e).__name__}: {str(e)}")

    def _is_trusted_source(self, ip: str) -> bool:
        return _h_is_trusted_source(ip, getattr(self, 'local_ips', set()), self.whitelist)

    def _post_process_alert(self, key, prob, state) -> bool:
        return self.alert_manager.should_alert(key, prob, state, self.local_ips, self.window)

    def _predict_and_alert(self):
        while self.running:
            time.sleep(self.window)
            with self.lock:
                if not self.flows:
                    continue

                # L·ªçc c√°c lu·ªìng ch∆∞a ƒë·ªß s·ªë g√≥i / bytes t·ªëi thi·ªÉu
                filtered_flows = {}
                
                # üî• NEW: Track flows per destination (for --rand-source detection)
                dst_flow_tracker = defaultdict(list)  # {(dip, dport, proto): [flow_keys]}
                
                for k, state in list(self.flows.items()):
                    sip, sport, dip, dport, proto = k
                    total_pkts = state.pkt_src + state.pkt_dst
                    total_bytes = state.src_bytes + state.dst_bytes
                    
                    # Ch·ªâ b·ªè qua LOCAL server response (c·∫£ SIP v√† DIP ƒë·ªÅu local)
                    if self._is_local_ip(sip) and self._is_local_ip(dip) and sport < 1024:
                        continue
                    
                    # Track flows targeting same destination
                    if not self._is_local_ip(sip) and self._is_local_ip(dip):
                        dst_key = (dip, dport, proto)
                        dst_flow_tracker[dst_key].append(k)
                    
                    # S·ª≠ d·ª•ng logic th√¥ng minh: classify c·∫£ flow l·ªõn V√Ä flow nh·ªè t·ª´ IP nghi ng·ªù
                    flow_data = {
                        'packet_count': total_pkts,
                        'total_bytes': total_bytes
                    }
                    if self._should_classify(k, flow_data):
                        filtered_flows[k] = state
                
                # üî• Check if destination is under attack (many sources ‚Üí one target)
                for dst_key, flow_keys in dst_flow_tracker.items():
                    if len(flow_keys) > self.flow_classifier.global_flow_threshold:
                        # Add all flows to classification queue (DDoS/spoofed-IP)
                        for fk in flow_keys:
                            if fk not in filtered_flows and fk in self.flows:
                                filtered_flows[fk] = self.flows[fk]
                
                # Flow classification complete

                if not filtered_flows:
                    self.flows.clear()
                    continue

                self.stats["flows_analyzed"] += len(filtered_flows)

                # Ch·∫°y flood detector ph√¢n t√°n tr√™n t·∫≠p lu·ªìng ƒë√£ ƒë·ªß ƒëi·ªÅu ki·ªán
                self.syn_flood_dist.process_aggregated(
                    filtered_flows,
                    is_local_ip_fn=self._is_local_ip,
                    window_seconds=self.window,
                    attack_logger=self.attack_logger,
                    alert_queue=self.alert_manager.alert_queue,
                    recent_alerts=self.alert_manager.recent_alerts,
                    stats=self.stats,
                )
                self.udp_flood_dist.process_aggregated(
                    filtered_flows,
                    is_local_ip_fn=self._is_local_ip,
                    window_seconds=self.window,
                    attack_logger=self.attack_logger,
                    alert_queue=self.alert_manager.alert_queue,
                    recent_alerts=self.alert_manager.recent_alerts,
                    stats=self.stats,
                )
                self.icmp_flood_dist.process_aggregated(
                    filtered_flows,
                    is_local_ip_fn=self._is_local_ip,
                    window_seconds=self.window,
                    attack_logger=self.attack_logger,
                    alert_queue=self.alert_manager.alert_queue,
                    recent_alerts=self.alert_manager.recent_alerts,
                    stats=self.stats,
                )

                # Chuy·ªÉn FlowState -> vector ƒë·∫∑c tr∆∞ng
                host_counts = self._build_host_counts()
                rows, keys, states = [], [], []
                for k, st in list(filtered_flows.items()):
                    rows.append(st.to_feature_row(k, host_counts))
                    keys.append(k)
                    states.append(st)

                if not rows:
                    self.flows.clear()
                    continue

                df = pd.DataFrame(rows)
                for col in ["duration","src_bytes","dst_bytes","count","srv_count","dst_host_count","dst_host_srv_count"]:
                    if col not in df:
                        df[col] = 0.0
                
                # üÜï Drop new features n·∫øu model ch∆∞a ƒë∆∞·ª£c retrain
                # Model hi·ªán t·∫°i ch·ªâ bi·∫øt 41 features g·ªëc
                new_features = ['rej_rate', 'syn_ratio', 'syn_ack_ratio', 
                               'packet_imbalance', 'byte_imbalance', 'small_packet_ratio']
                for feat in new_features:
                    if feat in df.columns:
                        df = df.drop(columns=[feat])

                X = self.preprocess.transform(df)
                probs = self._predict_probabilities(X).ravel()
                preds = (probs >= self.alert_threshold).astype(int)

                # Generate alerts for flows exceeding threshold
                alert_count = 0

                # Apply confidence boosting and rule-based fallback
                boosted_probs = self.flow_classifier.boost_probabilities(keys, probs, states, self.min_pkts)
                probs = np.array(boosted_probs)
                preds = (probs >= self.alert_threshold).astype(int)
                preds = self.flow_classifier.apply_rule_based_fallback(keys, probs, states, preds, self.min_pkts)

                
                # Generate alerts using AlertManager (group by attack type)
                attack_summary = {}  # {(dst, proto, attack_type): [flows]}
                
                for k, p, pr, st in zip(keys, preds, probs, states):
                    if p == 1 and self._post_process_alert(k, pr, st):
                        sip, sport, dip, dport, proto = k
                        attack_type = self._determine_attack_type(k, st)
                        
                        # Group attacks by destination + protocol + type
                        attack_key = (dip, dport, proto, attack_type)
                        if attack_key not in attack_summary:
                            attack_summary[attack_key] = []
                        attack_summary[attack_key].append((k, pr, st))
                
                # Generate one alert per attack group
                for attack_key, flows in attack_summary.items():
                    dip, dport, proto, attack_type = attack_key
                    
                    # Pick representative flow (highest probability)
                    flows.sort(key=lambda x: x[1], reverse=True)
                    best_flow = flows[0]
                    k, pr, st = best_flow
                    
                    # Generate grouped alert with flow count
                    if self.alert_manager.generate_alert(k, pr, st, attack_type, self.local_ips, flow_count=len(flows)):
                        alert_count += 1

                if alert_count > 0:
                    print(f"[*] Generated {alert_count} attack alerts this window")

                # Reset to√†n b·ªô state ƒë·ªÉ chu·∫©n b·ªã c·ª≠a s·ªï k·∫ø ti·∫øp
                self.flows.clear()

    def _determine_attack_type(self, key, state) -> str:
        return _h_determine_attack_type(key, state)

    def start(self) -> bool:
        if self.running:
            return False
        
        if not hasattr(self, 'model') or self.model is None:
            if not self.load_model():
                return False

        self.running = True
        self.stats["start_time"] = time.time()

        self.predict_thread = threading.Thread(target=self._predict_and_alert, daemon=True)
        self.predict_thread.start()

        def start_sniffing():
            ifaces = [i.strip() for i in str(self.iface).split(',') if i.strip()]
            iface_arg = ifaces if len(ifaces) > 1 else (ifaces[0] if ifaces else None)
            sniff(iface=iface_arg, prn=self._packet_cb, store=False, stop_filter=lambda x: not self.running)

        self.sniff_thread = threading.Thread(target=start_sniffing, daemon=True)
        self.sniff_thread.start()

        print(f"[*] IDS started: {self.iface}, window={self.window}s, threshold={self.alert_threshold}")
        return True

    def stop(self):
        if not self.running:
            return
        self.running = False
        if self.predict_thread and self.predict_thread.is_alive():
            self.predict_thread.join(timeout=2)
        print("[*] IDS stopped")

    def get_stats(self):
        stats = self.stats.copy()
        if stats["start_time"]:
            stats["uptime"] = time.time() - stats["start_time"]
        else:
            stats["uptime"] = 0
        return stats

    def get_recent_alerts(self):
        return self.alert_manager.get_recent_alerts()

    def get_next_alert(self, timeout: float = 0.1):
        try:
            return self.alert_manager.alert_queue.get(timeout=timeout)
        except queue.Empty:
            return None


# Singleton instance
_ids_instance = None

def get_ids_instance(config_path: str = 'config.ini') -> IDSEngine:
    global _ids_instance
    if _ids_instance is None:
        _ids_instance = IDSEngine(config_path)
    return _ids_instance